{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of various algorithms on metrics\n",
    "\n",
    "This notebook for running algorithms:\n",
    "* Logistic Regression\n",
    "* SVM\n",
    "* Random Forests\n",
    "* Artificial neural network\n",
    "\n",
    "and scores them based on metrics:\n",
    "* Accuracy\n",
    "* F1 Score\n",
    "* ROC AUC\n",
    "* Precision\n",
    "* Recall\n",
    "\n",
    "Runs each algorithm for each dataset across 5 trials, where GridSearch is used to find the optimal hyperparameters for each metric, then runs the classifier on training/testing sets and takes the mean over 5 trials. \n",
    "\n",
    "Results are then stored in the results folder of this directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# import needed functions\n",
    "from preprocess import prep_airlines, prep_income, prep_phishing, prep_surgical\n",
    "from bootstrap import bootstrap\n",
    "from logistic_regression import run_logistic_regression\n",
    "from random_forest import run_random_forests\n",
    "from support_vector import run_svm\n",
    "from artificial_nn import run_ann\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define datasets and metrics to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets and metrics\n",
    "datasets = ['airline', 'income', 'phishing', 'surgical']\n",
    "metrics = ['accuracy', 'f1', 'roc_auc', 'precision', 'recall']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIRLINE\n",
      "----------------------------------\n",
      "Trial 1 done\n",
      "Trial 2 done\n",
      "Trial 3 done\n",
      "Trial 4 done\n",
      "Trial 5 done\n",
      "\n",
      "INCOMES\n",
      "----------------------------------\n",
      "Trial 1 done\n",
      "Trial 2 done\n",
      "Trial 3 done\n",
      "Trial 4 done\n",
      "Trial 5 done\n",
      "\n",
      "PHISHING\n",
      "----------------------------------\n",
      "Trial 1 done\n",
      "Trial 2 done\n",
      "Trial 3 done\n",
      "Trial 4 done\n",
      "Trial 5 done\n",
      "\n",
      "SURGICAL\n",
      "----------------------------------\n",
      "Trial 1 done\n",
      "Trial 2 done\n",
      "Trial 3 done\n",
      "Trial 4 done\n",
      "Trial 5 done\n"
     ]
    }
   ],
   "source": [
    "# final values\n",
    "logreg_results_train = np.zeros((len(datasets), len(metrics)))\n",
    "logreg_results_test = np.zeros((len(datasets), len(metrics)))\n",
    "logreg_hyperparams = [] # list of dataframes\n",
    "\n",
    "# for each dataset: run trials and add to final results\n",
    "\n",
    "# AIRLINE\n",
    "print('AIRLINE\\n----------------------------------')\n",
    "X,y = prep_airlines()\n",
    "train, test, hypers = run_logistic_regression(X,y)\n",
    "\n",
    "logreg_results_train[0,:] = train\n",
    "logreg_results_test[0,:] = test\n",
    "logreg_hyperparams.append(hypers)\n",
    "\n",
    "# INCOMES\n",
    "print('\\nINCOMES\\n----------------------------------')\n",
    "X,y = prep_income()\n",
    "train, test, hypers = run_logistic_regression(X,y)\n",
    "\n",
    "logreg_results_train[1,:] = train\n",
    "logreg_results_test[1,:] = test\n",
    "logreg_hyperparams.append(hypers)\n",
    "\n",
    "# PHISHING\n",
    "print('\\nPHISHING\\n----------------------------------')\n",
    "X,y = prep_phishing()\n",
    "train, test, hypers = run_logistic_regression(X,y)\n",
    "\n",
    "logreg_results_train[2,:] = train\n",
    "logreg_results_test[2,:] = test\n",
    "logreg_hyperparams.append(hypers)\n",
    "\n",
    "# SURGICAL\n",
    "print('\\nSURGICAL\\n----------------------------------')\n",
    "X,y = prep_surgical()\n",
    "train, test, hypers = run_logistic_regression(X,y)\n",
    "\n",
    "logreg_results_train[3,:] = train\n",
    "logreg_results_test[3,:] = test\n",
    "logreg_hyperparams.append(hypers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to results folder\n",
    "result_dir = './results/'\n",
    "\n",
    "df_results_train = pd.DataFrame(logreg_results_train, columns=metrics, index=datasets)\n",
    "df_results_train['mean'] = np.mean(df_results_train, axis=1)\n",
    "df_results_train.to_csv(result_dir+'logreg_results_train.csv')\n",
    "\n",
    "df_results_test = pd.DataFrame(logreg_results_test, columns=metrics, index=datasets)\n",
    "df_results_test['mean'] = np.mean(df_results_test, axis=1)\n",
    "df_results_test.to_csv(result_dir+'logreg_results_test.csv')\n",
    "\n",
    "df_hyperparams = pd.concat(logreg_hyperparams)\n",
    "df_hyperparams.to_csv(result_dir+'logreg_hyperparameters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to visualize hyperparameter search results\n",
    "for i,hyp in enumerate(logreg_hyperparams):\n",
    "    sns.heatmap(hyp, annot=True, cmap='viridis')\n",
    "    plt.title(datasets[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIRLINE\n",
      "----------------------------------\n",
      "Trial 1 done\n",
      "Trial 2 done\n",
      "Trial 3 done\n",
      "Trial 4 done\n",
      "Trial 5 done\n",
      "\n",
      "INCOMES\n",
      "----------------------------------\n",
      "Trial 1 done\n",
      "Trial 2 done\n",
      "Trial 3 done\n",
      "Trial 4 done\n",
      "Trial 5 done\n",
      "\n",
      "PHISHING\n",
      "----------------------------------\n",
      "Trial 1 done\n",
      "Trial 2 done\n",
      "Trial 3 done\n",
      "Trial 4 done\n",
      "Trial 5 done\n",
      "\n",
      "SURGICAL\n",
      "----------------------------------\n",
      "Trial 1 done\n",
      "Trial 2 done\n",
      "Trial 3 done\n",
      "Trial 4 done\n",
      "Trial 5 done\n"
     ]
    }
   ],
   "source": [
    "# final values\n",
    "svm_results_train = np.zeros((len(datasets), len(metrics)))\n",
    "svm_results_test = np.zeros((len(datasets), len(metrics)))\n",
    "\n",
    "# for each dataset: run trials and add to final results\n",
    "\n",
    "# AIRLINE\n",
    "print('AIRLINE\\n----------------------------------')\n",
    "X,y = prep_airlines()\n",
    "train, test = run_svm(X,y)\n",
    "\n",
    "svm_results_train[0,:] = train\n",
    "svm_results_test[0,:] = test\n",
    "\n",
    "# INCOMES\n",
    "print('\\nINCOMES\\n----------------------------------')\n",
    "X,y = prep_income()\n",
    "train, test = run_svm(X,y)\n",
    "\n",
    "svm_results_train[1,:] = train\n",
    "svm_results_test[1,:] = test\n",
    "\n",
    "# PHISHING\n",
    "print('\\nPHISHING\\n----------------------------------')\n",
    "X,y = prep_phishing()\n",
    "train, test = run_svm(X,y)\n",
    "\n",
    "svm_results_train[2,:] = train\n",
    "svm_results_test[2,:] = test\n",
    "\n",
    "# SURGICAL\n",
    "print('\\nSURGICAL\\n----------------------------------')\n",
    "X,y = prep_surgical()\n",
    "train, test = run_svm(X,y)\n",
    "\n",
    "svm_results_train[3,:] = train\n",
    "svm_results_test[3,:] = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to results folder\n",
    "result_dir = './results/'\n",
    "\n",
    "df_results_train = pd.DataFrame(svm_results_train, columns=metrics, index=datasets)\n",
    "df_results_train['mean'] = np.mean(df_results_train, axis=1)\n",
    "df_results_train.to_csv(result_dir+'svm_results_train.csv')\n",
    "\n",
    "df_results_test = pd.DataFrame(svm_results_test, columns=metrics, index=datasets)\n",
    "df_results_test['mean'] = np.mean(df_results_test, axis=1)\n",
    "df_results_test.to_csv(result_dir+'svm_results_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIRLINE\n",
      "----------------------------------\n",
      "Trial 1 done\n",
      "Trial 2 done\n",
      "Trial 3 done\n",
      "Trial 4 done\n",
      "Trial 5 done\n",
      "\n",
      "INCOMES\n",
      "----------------------------------\n",
      "Trial 1 done\n",
      "Trial 2 done\n",
      "Trial 3 done\n",
      "Trial 4 done\n",
      "Trial 5 done\n",
      "\n",
      "PHISHING\n",
      "----------------------------------\n",
      "Trial 1 done\n",
      "Trial 2 done\n",
      "Trial 3 done\n",
      "Trial 4 done\n",
      "Trial 5 done\n",
      "\n",
      "SURGICAL\n",
      "----------------------------------\n",
      "Trial 1 done\n",
      "Trial 2 done\n",
      "Trial 3 done\n",
      "Trial 4 done\n",
      "Trial 5 done\n"
     ]
    }
   ],
   "source": [
    "# final values\n",
    "rf_results_train = np.zeros((len(datasets), len(metrics)))\n",
    "rf_results_test = np.zeros((len(datasets), len(metrics)))\n",
    "rf_hyperparams = [] # list of dataframes\n",
    "\n",
    "# for each dataset: run trials and add to final results\n",
    "\n",
    "# AIRLINE\n",
    "print('AIRLINE\\n----------------------------------')\n",
    "X,y = prep_airlines()\n",
    "train, test, hypers = run_random_forests(X,y)\n",
    "\n",
    "rf_results_train[0,:] = train\n",
    "rf_results_test[0,:] = test\n",
    "rf_hyperparams.append(hypers)\n",
    "\n",
    "# INCOMES\n",
    "print('\\nINCOMES\\n----------------------------------')\n",
    "X,y = prep_income()\n",
    "train, test, hypers = run_random_forests(X,y)\n",
    "\n",
    "rf_results_train[1,:] = train\n",
    "rf_results_test[1,:] = test\n",
    "rf_hyperparams.append(hypers)\n",
    "\n",
    "# PHISHING\n",
    "print('\\nPHISHING\\n----------------------------------')\n",
    "X,y = prep_phishing()\n",
    "train, test, hypers = run_random_forests(X,y)\n",
    "\n",
    "rf_results_train[2,:] = train\n",
    "rf_results_test[2,:] = test\n",
    "rf_hyperparams.append(hypers)\n",
    "\n",
    "# SURGICAL\n",
    "print('\\nSURGICAL\\n----------------------------------')\n",
    "X,y = prep_surgical()\n",
    "train, test, hypers = run_random_forests(X,y)\n",
    "\n",
    "rf_results_train[3,:] = train\n",
    "rf_results_test[3,:] = test\n",
    "rf_hyperparams.append(hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to results folder\n",
    "result_dir = './results/'\n",
    "\n",
    "df_results_train = pd.DataFrame(rf_results_train, columns=metrics, index=datasets)\n",
    "df_results_train['mean'] = np.mean(df_results_train, axis=1)\n",
    "df_results_train.to_csv(result_dir+'rf_results_train.csv')\n",
    "\n",
    "df_results_test = pd.DataFrame(rf_results_test, columns=metrics, index=datasets)\n",
    "df_results_test['mean'] = np.mean(df_results_test, axis=1)\n",
    "df_results_test.to_csv(result_dir+'rf_results_test.csv')\n",
    "\n",
    "df_hyperparams = pd.concat(rf_hyperparams)\n",
    "df_hyperparams.to_csv(result_dir+'rf_hyperparameters.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artifical Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIRLINE\n",
      "----------------------------------\n",
      "Trial 1 done\n",
      "Trial 2 done\n",
      "Trial 3 done\n",
      "Trial 4 done\n",
      "Trial 5 done\n",
      "\n",
      "INCOMES\n",
      "----------------------------------\n",
      "Trial 1 done\n",
      "Trial 2 done\n",
      "Trial 3 done\n",
      "Trial 4 done\n",
      "Trial 5 done\n",
      "\n",
      "PHISHING\n",
      "----------------------------------\n",
      "Trial 1 done\n",
      "Trial 2 done\n",
      "Trial 3 done\n",
      "Trial 4 done\n",
      "Trial 5 done\n",
      "\n",
      "SURGICAL\n",
      "----------------------------------\n",
      "Trial 1 done\n",
      "Trial 2 done\n",
      "Trial 3 done\n",
      "Trial 4 done\n",
      "Trial 5 done\n"
     ]
    }
   ],
   "source": [
    "# final values\n",
    "ann_results_train = np.zeros((len(datasets), len(metrics)))\n",
    "ann_results_test = np.zeros((len(datasets), len(metrics)))\n",
    "ann_hyperparams = [] # list of dataframes\n",
    "\n",
    "# for each dataset: run trials and add to final results\n",
    "\n",
    "# AIRLINE\n",
    "print('AIRLINE\\n----------------------------------')\n",
    "X,y = prep_airlines()\n",
    "train, test, hypers = run_ann(X,y)\n",
    "\n",
    "ann_results_train[0,:] = train\n",
    "ann_results_test[0,:] = test\n",
    "ann_hyperparams.append(hypers)\n",
    "\n",
    "# INCOMES\n",
    "print('\\nINCOMES\\n----------------------------------')\n",
    "X,y = prep_income()\n",
    "# doesn't work with non-scaled values of second feature\n",
    "scaler = StandardScaler()\n",
    "X[:,1] = scaler.fit_transform(X[:,1].reshape(-1,1)).reshape(-1)\n",
    "train, test, hypers = run_ann(X,y)\n",
    "\n",
    "ann_results_train[1,:] = train\n",
    "ann_results_test[1,:] = test\n",
    "ann_hyperparams.append(hypers)\n",
    "\n",
    "# PHISHING\n",
    "print('\\nPHISHING\\n----------------------------------')\n",
    "X,y = prep_phishing()\n",
    "train, test, hypers = run_ann(X,y)\n",
    "\n",
    "ann_results_train[2,:] = train\n",
    "ann_results_test[2,:] = test\n",
    "ann_hyperparams.append(hypers)\n",
    "\n",
    "# SURGICAL\n",
    "print('\\nSURGICAL\\n----------------------------------')\n",
    "X,y = prep_surgical()\n",
    "train, test, hypers = run_ann(X,y)\n",
    "\n",
    "ann_results_train[3,:] = train\n",
    "ann_results_test[3,:] = test\n",
    "ann_hyperparams.append(hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to results folder\n",
    "result_dir = './results/'\n",
    "\n",
    "df_results_train = pd.DataFrame(ann_results_train, columns=metrics, index=datasets)\n",
    "df_results_train['mean'] = np.mean(df_results_train, axis=1)\n",
    "df_results_train.to_csv(result_dir+'ann_results_train.csv')\n",
    "\n",
    "df_results_test = pd.DataFrame(ann_results_test, columns=metrics, index=datasets)\n",
    "df_results_test['mean'] = np.mean(df_results_test, axis=1)\n",
    "df_results_test.to_csv(result_dir+'ann_results_test.csv')\n",
    "\n",
    "df_hyperparams = pd.concat(ann_hyperparams)\n",
    "df_hyperparams.to_csv(result_dir+'ann_hyperparameters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
